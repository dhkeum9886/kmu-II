import sys
from konlp.kma.klt2023 import klt2023
from collections import Counter, defaultdict

#
# simple_txt = "ë‚´ ëˆˆì„ ë³¸ë‹¤ë©´ ë°¤í•˜ëŠ˜ì˜ ë³„ì´ ë˜ëŠ” ê¸°ë¶„ì„ ëŠë‚„ ìˆ˜ ìˆì„ ê±°ì•¼"
# print(u'\n0. KLT2000 ë¶„ì„ ê²°ê³¼')
# print(k.pos(simple_txt))
# print(k.morphs(simple_txt))
# print(k.nouns(simple_txt))


def text_mining(lines):
    result = []
    klt = klt2023()
    for line in lines:
        result.extend(klt.nouns(line))
    return result


def read():
    def input_file(filename):
        lines = []
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                for line_number, line in enumerate(f, start=1):
                    if len(line.strip()) > 0:
                        lines.append(line.strip())
        except FileNotFoundError:
            print(f"Error: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ -> {filename}")
            sys.exit(1)
        finally:
            return lines

    input_path = sys.argv[1]
    return input_file(input_path)


# def top_words_in_dict(word_list, dictionary, top_n: int = 100):
#     dict_set = set(dictionary)
#     filtered = [word for word in word_list if word in dict_set]
#
#     counter = Counter(filtered)
#     return counter.most_common(top_n)


def init_dict():
    def dict_file(filename):
        emo_dict = {}
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                for line_number, line in enumerate(f, start=1):
                    if len(line.strip()) > 0:
                        # lines.append(line.strip())
                        print(line.strip())
                        splited = line.strip().split('\t')
                        emo_dict[splited[0]] = {
                            'cat': splited[1],
                            'con': splited[2],
                        }

        except FileNotFoundError:
            print(f"Error: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ -> {filename}")
            sys.exit(1)
        finally:
            return emo_dict

    dict_path = sys.argv[2]
    return dict_file(dict_path)


def analyze_emotions(word_list, emo_dict, top_n: int = 100):
    # 1) emo_dictì— ìˆëŠ” ë‹¨ì–´ë§Œ í•„í„°ë§
    filtered = [w for w in word_list if w in emo_dict]

    # 2) ë‹¨ì–´ë³„ ë“±ì¥ íšŸìˆ˜ ì§‘ê³„
    counts = Counter(filtered)

    # 3) ë‹¨ì–´â†’ì¹´í…Œê³ ë¦¬ ë§¤í•‘
    word_cat = {w: emo_dict[w]['cat'] for w in counts}

    # 4) Top N ë‹¨ì–´ì™€ ì¹´í…Œê³ ë¦¬ í•¨ê»˜ ë¬¶ê¸°
    most_common = counts.most_common(top_n)
    top_words = [(w, cnt, word_cat[w]) for w, cnt in most_common]

    # 5) ì¹´í…Œê³ ë¦¬ë³„ ë“±ì¥ íšŸìˆ˜ ì§‘ê³„
    cat_counts = Counter(word_cat[w] for w in filtered)
    cat_counts_list = cat_counts.most_common()

    return top_words, cat_counts_list


if __name__ == "__main__":
    if len(sys.argv) != 3:
        print(f"Usage: {sys.argv[0]} <input_file> <emotion_dict_file>")
        sys.exit(1)

    # input file
    lines = read()
    word_list = text_mining(lines)

    # emo file
    emo_dict = init_dict()
    # print('----------')
    # print(emo_dict)
    # word_list = ['í™©ì†¡ìŠ¤ëŸ½ë‹¤', 'í™©ì†¡ìŠ¤ëŸ½ë‹¤', 'í›¼ì†í•˜ë‹¤']

    top_words, cat_counts = analyze_emotions(word_list, emo_dict)

    # â—¼ Top words by frequency (ë‹¨ì–´, count, ì¹´í…Œê³ ë¦¬)
    print("â« Top words by frequency:")
    for word, count, cat in top_words:
        print(f"{word}: {count} ({cat})")

    # â—¼ Category counts
    print("\nğŸ· Category counts:")
    for cat, count in cat_counts:
        print(f"{cat}: {count}")

    ## TODO ê° íŒŒíŠ¸ ë³„ ê°ì • íŒŒì´ì°¨íŠ¸
    ## íŒŒíŠ¸ë³„ ê·¸ë˜í”„ ê°ì • ê·¸ë˜í”„